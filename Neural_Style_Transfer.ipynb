# Install required packages
!pip install torch torchvision pillow matplotlib
# Import necessary libraries
import torch
import torch.optim as optim
from torchvision import transforms, models
from PIL import Image
import matplotlib.pyplot as plt
import torchvision.transforms as T
from google.colab import files
import os

# Check for GPU availability and set device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
def upload_image():
    """
    Upload an image file in Google Colab.

    Returns:
        str: File path of the uploaded image.
    """
    uploaded = files.upload()
    file_name = list(uploaded.keys())[0]
    return f"/content/{file_name}"

def load_image(image_path, max_size=512):
    """
    Load and preprocess an image.

    Args:
        image_path (str): Path to the image.
        max_size (int): Maximum size for resizing the image.

    Returns:
        torch.Tensor: Preprocessed image tensor.
    """
    image = Image.open(image_path).convert('RGB')

    # Resize image to fit within specified size
    size = max(image.size)
    if size > max_size:
        size = max_size

    transform = transforms.Compose([
        transforms.Resize(size),
        transforms.ToTensor(),
        transforms.Lambda(lambda x: x.unsqueeze(0))  # Add batch dimension
    ])

    return transform(image).to(device)
detach().cpu().squeeze(0)
    image = transforms.ToPILImef imshow(tensor, title=None):
    """
    Display an image from a tensor.

    Args:
        tensor (torch.Tensor): Image tensor to display.
        title (str, optional): Title for the image. Defaults to None.
    """
    image = tensor.clone().dage()(image)
    plt.imshow(image)
    if title:
        plt.title(title)
    plt.show()
class ContentLoss(torch.nn.Module):
    """
    Compute Content Loss between the target and generated images.
    """
    def __init__(self, target):
        super(ContentLoss, self).__init__()
        self.target = target.detach()

    def forward(self, x):
        self.loss = torch.nn.functional.mse_loss(x, self.target)
        return x
def gram_matrix(x):
    """
    Calculate the Gram matrix for style representation.

    Args:
        x (torch.Tensor): Input tensor.

    Returns:
        torch.Tensor: Gram matrix of the input tensor.
    """
    b, c, h, w = x.size()
    features = x.view(b * c, h * w)
    gram = torch.mm(features, features.t())
    return gram.div(b * c * h * w)


class StyleLoss(torch.nn.Module):
    """
    Compute Style Loss between the target and generated images.
    """
    def __init__(self, target_feature):
        super(StyleLoss, self).__init__()
        self.target = gram_matrix(target_feature).detach()

    def forward(self, x):
        gram = gram_matrix(x)
        self.loss = torch.nn.functional.mse_loss(gram, self.target)
        return x
def get_vgg_model():
    """
    Load the pre-trained VGG19 model for feature extraction.

    Returns:
        torch.nn.Module: VGG19 model with required layers.
    """
    vgg = models.vgg19(pretrained=True).features.to(device).eval()

    # Define the layers for content and style loss
    content_layers = ['conv_4']
    style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']

    model = torch.nn.Sequential()
    content_losses = []
    style_losses = []

    i = 0
    for layer in vgg.children():
        if isinstance(layer, torch.nn.Conv2d):
            i += 1
            name = f"conv_{i}"
        elif isinstance(layer, torch.nn.ReLU):
            name = f"relu_{i}"
            layer = torch.nn.ReLU(inplace=False)
        elif isinstance(layer, torch.nn.MaxPool2d):
            name = f"pool_{i}"
        elif isinstance(layer, torch.nn.BatchNorm2d):
            name = f"bn_{i}"
        else:
            continue

        model.add_module(name, layer)

        if name in content_layers:
            target = model(content_image).detach()
            content_loss = ContentLoss(target)
            model.add_module(f"content_loss_{i}", content_loss)
            content_losses.append(content_loss)

        if name in style_layers:
            target = model(style_image).detach()
            style_loss = StyleLoss(target)
            model.add_module(f"style_loss_{i}", style_loss)
            style_losses.append(style_loss)

    return model, content_losses, style_losses
def run_style_transfer(model, content_losses, style_losses, input_image, num_steps=300,
                        style_weight=1000000, content_weight=1):
    """
    Run the style transfer algorithm.

    Args:
        model (torch.nn.Module): VGG19 model with added losses.
        content_losses (list): Content loss modules.
        style_losses (list): Style loss modules.
        input_image (torch.Tensor): Input tensor for style transfer.
        num_steps (int): Number of iterations for optimization.
        style_weight (float): Weight for style loss.
        content_weightd (float): Weight for content loss.

    Returns:
        torch.Tensor: Styled image tensor.
    """
    input_image.requires_grad_(True)
    optimizer = optim.LBFGS([input_image])

    step = [0]
    while step[0] <= num_steps:
        def closure():
            input_image.data.clamp_(0, 1)
            optimizer.zero_grad()
            model(input_image)

            style_score = 0
            content_score = 0

            # Compute losses
            for sl in style_losses:
                style_score += sl.loss
            for cl in content_losses:
                content_score += cl.loss

            style_score *= style_weight
            content_score *= content_weight
            loss = style_score + content_score
            loss.backward()

            step[0] += 1
            if step[0] % 50 == 0:
                print(f"Step {step[0]}: Style Loss: {style_score.item():.4f}, Content Loss: {content_score.item():.4f}")

            return loss

        optimizer.step(closure)

    input_image.data.clamp_(0, 1)
    return input_image
def main():
    """
    Main function to run the neural style transfer.
    """
    # Upload content and style images
    print("Upload the content image:")
    content_path = upload_image()
    print("Upload the style image:")
    style_path = upload_image()

    # Load images
    global content_image, style_image
    content_image = load_image(content_path)
    style_image = load_image(style_path, max_size=512)

    # Display original images
    print("\nOriginal Content Image:")
    imshow(content_image, title="Content Image")
    print("\nOriginal Style Image:")
    imshow(style_image, title="Style Image")

    # Load VGG19 model and content/style losses
    model, content_losses, style_losses = get_vgg_model()

    # Create input image as a copy of content image
    input_image = content_image.clone()

    # Run style transfer
    output = run_style_transfer(model, content_losses, style_losses, input_image)

    # Display the result
    print("\n--- Final Stylized Image ---")
    imshow(output, title="Styled Image")

    # Save the final output
    output_image = transforms.ToPILImage()(output.cpu().squeeze(0))
    output_image.save("/content/stylized_image.jpg")
    print("Stylized image saved as 'stylized_image.jpg'")
if __name__ == "__main__":
    main()
